[2025-10-17T19:06:13.326+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-10-17T19:06:13.378+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jobs_jobspy_daily.collect_jobspy manual__2025-10-17T19:06:12.353662+00:00 [queued]>
[2025-10-17T19:06:13.388+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jobs_jobspy_daily.collect_jobspy manual__2025-10-17T19:06:12.353662+00:00 [queued]>
[2025-10-17T19:06:13.390+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-10-17T19:06:13.406+0000] {taskinstance.py:2330} INFO - Executing <Task(BashOperator): collect_jobspy> on 2025-10-17 19:06:12.353662+00:00
[2025-10-17T19:06:13.414+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'jobs_jobspy_daily', 'collect_jobspy', 'manual__2025-10-17T19:06:12.353662+00:00', '--job-id', '51', '--raw', '--subdir', 'DAGS_FOLDER/jobs_jobspy_daily.py', '--cfg-path', '/tmp/tmpr52_49xt']
[2025-10-17T19:06:13.417+0000] {standard_task_runner.py:91} INFO - Job 51: Subtask collect_jobspy
[2025-10-17T19:06:13.418+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62 DeprecationWarning: This process (pid=589) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-17T19:06:13.419+0000] {standard_task_runner.py:64} INFO - Started process 590 to run task
[2025-10-17T19:06:13.502+0000] {task_command.py:426} INFO - Running <TaskInstance: jobs_jobspy_daily.collect_jobspy manual__2025-10-17T19:06:12.353662+00:00 [running]> on host 68cd41389e54
[2025-10-17T19:06:13.667+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='jobs_jobspy_daily' AIRFLOW_CTX_TASK_ID='collect_jobspy' AIRFLOW_CTX_EXECUTION_DATE='2025-10-17T19:06:12.353662+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-17T19:06:12.353662+00:00'
[2025-10-17T19:06:13.668+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-10-17T19:06:13.686+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-17T19:06:13.691+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', "python /workspace/scripts/jobspy_collect.py --queries 'Data Engineer,Data Scientist,ML Engineer,DevOps Engineer,Backend Developer,Data Analyst' --locations 'France,Remote,Paris,Lyon' --sites indeed,glassdoor,linkedin --pages 8 --days 45"]
[2025-10-17T19:06:13.701+0000] {subprocess.py:86} INFO - Output:
[2025-10-17T19:07:35.047+0000] {subprocess.py:93} INFO - 2025-10-17 19:07:35,045 - INFO - JobSpy:Linkedin - finished scraping
[2025-10-17T19:13:25.882+0000] {subprocess.py:93} INFO - Wrote 925 rows to /workspace/datalake/raw/jobs/jobspy_Data_Engineer_France.jsonl
[2025-10-17T19:13:25.888+0000] {subprocess.py:93} INFO - Wrote 458 rows to /workspace/datalake/raw/jobs/jobspy_Data_Engineer_Remote.jsonl
[2025-10-17T19:13:25.889+0000] {subprocess.py:93} INFO - Wrote 718 rows to /workspace/datalake/raw/jobs/jobspy_Data_Engineer_Paris.jsonl
[2025-10-17T19:13:25.891+0000] {subprocess.py:93} INFO - Wrote 199 rows to /workspace/datalake/raw/jobs/jobspy_Data_Engineer_Lyon.jsonl
[2025-10-17T19:13:25.892+0000] {subprocess.py:93} INFO - Wrote 940 rows to /workspace/datalake/raw/jobs/jobspy_Data_Scientist_France.jsonl
[2025-10-17T19:13:25.893+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-10-17T19:13:25.894+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/jobspy/linkedin/__init__.py", line 157, in scrape
[2025-10-17T19:13:25.899+0000] {subprocess.py:93} INFO -     job_post = self._process_job(job_card, job_id, fetch_desc)
[2025-10-17T19:13:25.900+0000] {subprocess.py:93} INFO -                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-10-17T19:13:25.901+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/jobspy/linkedin/__init__.py", line 204, in _process_job
[2025-10-17T19:13:25.905+0000] {subprocess.py:93} INFO -     location = self._get_location(metadata_card)
[2025-10-17T19:13:25.906+0000] {subprocess.py:93} INFO -                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-10-17T19:13:25.908+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/jobspy/linkedin/__init__.py", line 320, in _get_location
[2025-10-17T19:13:25.910+0000] {subprocess.py:93} INFO -     country = Country.from_string(country)
[2025-10-17T19:13:25.911+0000] {subprocess.py:93} INFO -               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-10-17T19:13:25.913+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/jobspy/model.py", line 176, in from_string
[2025-10-17T19:13:25.914+0000] {subprocess.py:93} INFO -     raise ValueError(
[2025-10-17T19:13:25.916+0000] {subprocess.py:93} INFO - ValueError: Invalid country string: 'serbia'. Valid countries are: argentina, australia, austria, bahrain, bangladesh, belgium, bulgaria, brazil, canada, chile, china, colombia, costa rica, croatia, cyprus, czech republic,czechia, denmark, ecuador, egypt, estonia, finland, france, germany, greece, hong kong, hungary, india, indonesia, ireland, israel, italy, japan, kuwait, latvia, lithuania, luxembourg, malaysia, malta, mexico, morocco, netherlands, new zealand, nigeria, norway, oman, pakistan, panama, peru, philippines, poland, portugal, qatar, romania, saudi arabia, singapore, slovakia, slovenia, south africa, south korea, spain, sweden, switzerland, taiwan, thailand, türkiye,turkey, ukraine, united arab emirates, uk,united kingdom, usa,us,united states, uruguay, venezuela, vietnam, usa/ca, worldwide
[2025-10-17T19:13:25.918+0000] {subprocess.py:93} INFO - 
[2025-10-17T19:13:25.920+0000] {subprocess.py:93} INFO - During handling of the above exception, another exception occurred:
[2025-10-17T19:13:25.921+0000] {subprocess.py:93} INFO - 
[2025-10-17T19:13:25.923+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-10-17T19:13:25.924+0000] {subprocess.py:93} INFO -   File "/workspace/scripts/jobspy_collect.py", line 54, in <module>
[2025-10-17T19:13:25.925+0000] {subprocess.py:93} INFO -     main()
[2025-10-17T19:13:25.926+0000] {subprocess.py:93} INFO -   File "/workspace/scripts/jobspy_collect.py", line 30, in main
[2025-10-17T19:13:25.927+0000] {subprocess.py:93} INFO -     df = scrape_jobs(
[2025-10-17T19:13:25.928+0000] {subprocess.py:93} INFO -          ^^^^^^^^^^^^
[2025-10-17T19:13:25.928+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/jobspy/__init__.py", line 125, in scrape_jobs
[2025-10-17T19:13:25.929+0000] {subprocess.py:93} INFO -     site_value, scraped_data = future.result()
[2025-10-17T19:13:25.930+0000] {subprocess.py:93} INFO -                                ^^^^^^^^^^^^^^^
[2025-10-17T19:13:25.931+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
[2025-10-17T19:13:25.933+0000] {subprocess.py:93} INFO -     return self.__get_result()
[2025-10-17T19:13:25.934+0000] {subprocess.py:93} INFO -            ^^^^^^^^^^^^^^^^^^^
[2025-10-17T19:13:25.935+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
[2025-10-17T19:13:25.936+0000] {subprocess.py:93} INFO -     raise self._exception
[2025-10-17T19:13:25.936+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.12/concurrent/futures/thread.py", line 58, in run
[2025-10-17T19:13:25.937+0000] {subprocess.py:93} INFO -     result = self.fn(*self.args, **self.kwargs)
[2025-10-17T19:13:25.938+0000] {subprocess.py:93} INFO -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-10-17T19:13:25.939+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/jobspy/__init__.py", line 116, in worker
[2025-10-17T19:13:25.939+0000] {subprocess.py:93} INFO -     site_val, scraped_info = scrape_site(site)
[2025-10-17T19:13:25.940+0000] {subprocess.py:93} INFO -                              ^^^^^^^^^^^^^^^^^
[2025-10-17T19:13:25.941+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/jobspy/__init__.py", line 107, in scrape_site
[2025-10-17T19:13:25.941+0000] {subprocess.py:93} INFO -     scraped_data: JobResponse = scraper.scrape(scraper_input)
[2025-10-17T19:13:25.942+0000] {subprocess.py:93} INFO -                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-10-17T19:13:25.943+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/jobspy/linkedin/__init__.py", line 163, in scrape
[2025-10-17T19:13:25.944+0000] {subprocess.py:93} INFO -     raise LinkedInException(str(e))
[2025-10-17T19:13:25.944+0000] {subprocess.py:93} INFO - jobspy.exception.LinkedInException: Invalid country string: 'serbia'. Valid countries are: argentina, australia, austria, bahrain, bangladesh, belgium, bulgaria, brazil, canada, chile, china, colombia, costa rica, croatia, cyprus, czech republic,czechia, denmark, ecuador, egypt, estonia, finland, france, germany, greece, hong kong, hungary, india, indonesia, ireland, israel, italy, japan, kuwait, latvia, lithuania, luxembourg, malaysia, malta, mexico, morocco, netherlands, new zealand, nigeria, norway, oman, pakistan, panama, peru, philippines, poland, portugal, qatar, romania, saudi arabia, singapore, slovakia, slovenia, south africa, south korea, spain, sweden, switzerland, taiwan, thailand, türkiye,turkey, ukraine, united arab emirates, uk,united kingdom, usa,us,united states, uruguay, venezuela, vietnam, usa/ca, worldwide
[2025-10-17T19:13:26.237+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-10-17T19:13:26.256+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-10-17T19:13:26.464+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 243, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-10-17T19:13:26.511+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=jobs_jobspy_daily, task_id=collect_jobspy, run_id=manual__2025-10-17T19:06:12.353662+00:00, execution_date=20251017T190612, start_date=20251017T190613, end_date=20251017T191326
[2025-10-17T19:13:26.650+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 51 for task collect_jobspy (Bash command failed. The command returned a non-zero exit code 1.; 590)
[2025-10-17T19:13:26.688+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 1
[2025-10-17T19:13:26.814+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-17T19:13:26.825+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
